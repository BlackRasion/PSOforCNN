{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "import matplotlib.image as mpig\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载类\n",
    "class Mydata():\n",
    "    \"\"\"\n",
    "    数据加载和预处理\n",
    "    1. 读取图像文件\n",
    "    2. 调整图像大小为28x28\n",
    "    3. 处理标签\n",
    "    4. 生成one-hot编码\n",
    "    5. 划分训练集和测试集\n",
    "    \"\"\"\n",
    "    def __init__(self, files):\n",
    "        ims = []  # 存放以numpy格式的图片数据\n",
    "        labels = []  \n",
    "        for i in os.listdir(files):\n",
    "            if i.endswith('.jpg'):\n",
    "                im = mpig.imread(os.path.join(files, i), 0)\n",
    "                im = resize(im, (28, 28))                \n",
    "                l = i.replace('.jpg', '')\n",
    "                l = l.split('_')[-1]  # label最后一位9表示数字8\n",
    "                l = int(l) - 1\n",
    "                labels.append(l)\n",
    "                ims.append(im)\n",
    "        self.data = np.array(ims)[:, :, :, np.newaxis]\n",
    "        self.targets = np.array(labels)\n",
    "        self.targets_hot = self.onehot(self.targets, 15)\n",
    "    \n",
    "    # One-hot编码函数\n",
    "    def onehot(self, targets, num):\n",
    "        return np.eye(num)[targets]\n",
    "    \n",
    "    def train_test_split(self, test_size=0.3, random_state=None):\n",
    "        \"\"\"\n",
    "        划分训练集和测试集\n",
    "        :param test_size: 测试集比例\n",
    "        :param random_state: 随机种子\n",
    "        :return: 训练集和测试集的数据及标签\n",
    "        \"\"\"\n",
    "        X_train, X_test, y_train, y_test, y_train_hot, y_test_hot = train_test_split(\n",
    "            self.data, self.targets, self.targets_hot, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "        return X_train, y_train, y_train_hot, X_test, y_test, y_test_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# 数据可视化\\nplt.figure(figsize=(10, 10))\\nfor i in range(25):\\n    plt.subplot(5, 5, i+1)\\n    plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\\n    plt.title(str(y_train[i]))\\n    plt.axis('off')\\nplt.show()\\n\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "data = Mydata(r\"C:\\Users\\TheAssshOne\\Documents\\文件\\人工神经网络与深度学习\\AI\\data\")\n",
    "X_train, y_train, y_train_hot, X_test, y_test, y_test_hot = data.train_test_split(test_size=0.3, random_state=42)\n",
    "'''\n",
    "# 数据可视化\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(str(y_train[i]))\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoaders方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集图像数据\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)  \n",
    "X_train_tensor = X_train_tensor.permute(0, 3, 1, 2)  # 将 (10500, 28, 28, 1) 转换为 (10500, 1, 28, 28)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)     # 标签\n",
    "trainset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "# 测试集图像数据\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32) \n",
    "X_test_tensor = X_test_tensor.permute(0, 3, 1, 2)  # 将 (4500, 28, 28, 1) 转换为 (4500, 1, 28, 28)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)     # 标签\n",
    "testset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 4\n",
    "\n",
    "trainloader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "testloader = DataLoader(\n",
    "    testset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# 分类结果\n",
    "classes = [\n",
    "    \"零\", \"一\", \"二\", \"三\", \"四\",\n",
    "    \"五\", \"六\", \"七\", \"八\", \"九\",\n",
    "    \"十\", \"百\", \"千\", \"万\", \"亿\"\n",
    "]\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (max_pool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=120, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=84, out_features=15, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输入图像为1通道， 28x28尺寸\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() \n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.max_pool2d = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(16 * 4 * 4, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 15)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Convolution layer C1: 1 input image channel, 6 output channels,\n",
    "        # 5x5 square convolution, it uses RELU activation function, and\n",
    "        # outputs a Tensor with size (N, 6, 24, 24), where N is the size of the batch\n",
    "        c1 = self.max_pool2d(F.relu(self.conv1(input))) # Pool to (N, 6, 12, 12) Tensor output\n",
    "\n",
    "        # Convolution layer C2: 6 input channels, 16 output channels,\n",
    "        # 5x5 square convolution, it uses RELU activation function, and\n",
    "        # outputs a (N, 16, 8, 8) Tensor\n",
    "        c2 = self.max_pool2d(F.relu(self.conv2(c1))) # (N, 16, 4, 4) Tensor output\n",
    "\n",
    "        # Flatten operation: purely functional, outputs a (N, 256 = 16 * 4 * 4) Tensor\n",
    "        s3 = self.flatten(c2)\n",
    "\n",
    "        # Fully connected layer F5: (N, 256) Tensor input,\n",
    "        output = self.linear_relu_stack(s3) # (N, 15) Tensor output\n",
    "\n",
    "        return output\n",
    "\n",
    "net = Net()\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer and criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # 随机梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBorad Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "记录模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to show an image\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    生成预测结果和相应概率\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    显示网络的最高预测值及其概率，以及实际标签。\n",
    "    根据预测的正确与否为这些信息着色。\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\ML\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_utils.py:23: UserWarning: Glyph 20845 (\\N{CJK UNIFIED IDEOGRAPH-516D}) missing from font(s) DejaVu Sans.\n",
      "  canvas.draw()\n",
      "d:\\Code\\ML\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_utils.py:23: UserWarning: Glyph 20159 (\\N{CJK UNIFIED IDEOGRAPH-4EBF}) missing from font(s) DejaVu Sans.\n",
      "  canvas.draw()\n",
      "d:\\Code\\ML\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_utils.py:23: UserWarning: Glyph 30334 (\\N{CJK UNIFIED IDEOGRAPH-767E}) missing from font(s) DejaVu Sans.\n",
      "  canvas.draw()\n",
      "d:\\Code\\ML\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_utils.py:23: UserWarning: Glyph 21313 (\\N{CJK UNIFIED IDEOGRAPH-5341}) missing from font(s) DejaVu Sans.\n",
      "  canvas.draw()\n",
      "d:\\Code\\ML\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_utils.py:23: UserWarning: Glyph 38646 (\\N{CJK UNIFIED IDEOGRAPH-96F6}) missing from font(s) DejaVu Sans.\n",
      "  canvas.draw()\n",
      "d:\\Code\\ML\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_utils.py:23: UserWarning: Glyph 20061 (\\N{CJK UNIFIED IDEOGRAPH-4E5D}) missing from font(s) DejaVu Sans.\n",
      "  canvas.draw()\n",
      "d:\\Code\\ML\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_utils.py:23: UserWarning: Glyph 19968 (\\N{CJK UNIFIED IDEOGRAPH-4E00}) missing from font(s) DejaVu Sans.\n",
      "  canvas.draw()\n",
      "d:\\Code\\ML\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_utils.py:23: UserWarning: Glyph 20108 (\\N{CJK UNIFIED IDEOGRAPH-4E8C}) missing from font(s) DejaVu Sans.\n",
      "  canvas.draw()\n",
      "d:\\Code\\ML\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_utils.py:23: UserWarning: Glyph 19975 (\\N{CJK UNIFIED IDEOGRAPH-4E07}) missing from font(s) DejaVu Sans.\n",
      "  canvas.draw()\n",
      "d:\\Code\\ML\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_utils.py:23: UserWarning: Glyph 19971 (\\N{CJK UNIFIED IDEOGRAPH-4E03}) missing from font(s) DejaVu Sans.\n",
      "  canvas.draw()\n",
      "d:\\Code\\ML\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_utils.py:23: UserWarning: Glyph 22235 (\\N{CJK UNIFIED IDEOGRAPH-56DB}) missing from font(s) DejaVu Sans.\n",
      "  canvas.draw()\n",
      "d:\\Code\\ML\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_utils.py:23: UserWarning: Glyph 19977 (\\N{CJK UNIFIED IDEOGRAPH-4E09}) missing from font(s) DejaVu Sans.\n",
      "  canvas.draw()\n",
      "d:\\Code\\ML\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_utils.py:23: UserWarning: Glyph 20843 (\\N{CJK UNIFIED IDEOGRAPH-516B}) missing from font(s) DejaVu Sans.\n",
      "  canvas.draw()\n",
      "d:\\Code\\ML\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_utils.py:23: UserWarning: Glyph 20116 (\\N{CJK UNIFIED IDEOGRAPH-4E94}) missing from font(s) DejaVu Sans.\n",
      "  canvas.draw()\n",
      "d:\\Code\\ML\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_utils.py:23: UserWarning: Glyph 21315 (\\N{CJK UNIFIED IDEOGRAPH-5343}) missing from font(s) DejaVu Sans.\n",
      "  canvas.draw()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 7 # 训练次数\n",
    "\n",
    "running_loss = 0.0\n",
    "for epoch in range(epochs):\n",
    "    for batch, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        # forward\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch % 1000 == 999: # every 1000 mini-batches\n",
    "\n",
    "            # log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + batch)\n",
    "            \n",
    "            # log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + batch)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('Finished Training')\n",
    "writer.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for (images, labels) in testloader:\n",
    "        images = images.to(device)\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(labels)\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n",
    "\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    绘制相应的精确度-召回曲线\n",
    "    '''\n",
    "    tensorboard_truth = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_truth,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# 绘制所有类别的精确度-召回曲线\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           零       0.73      0.97      0.83       301\n",
      "           一       0.88      0.96      0.92       282\n",
      "           二       0.87      0.67      0.76       309\n",
      "           三       0.79      0.68      0.73       314\n",
      "           四       0.77      0.93      0.84       298\n",
      "           五       0.80      0.71      0.76       298\n",
      "           六       0.88      0.54      0.67       287\n",
      "           七       0.83      0.63      0.72       304\n",
      "           八       0.88      0.91      0.90       303\n",
      "           九       0.64      0.70      0.67       270\n",
      "           十       0.60      0.91      0.72       310\n",
      "           百       0.61      0.66      0.63       304\n",
      "           千       0.78      0.35      0.49       320\n",
      "           万       0.63      0.73      0.67       303\n",
      "           亿       0.75      0.89      0.81       297\n",
      "\n",
      "    accuracy                           0.75      4500\n",
      "   macro avg       0.76      0.75      0.74      4500\n",
      "weighted avg       0.76      0.75      0.74      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 输出打印分类报告\n",
    "from sklearn.metrics import classification_report\n",
    "y_true = y_test\n",
    "\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for (images, labels) in testloader:\n",
    "        images = images.to(device)\n",
    "        output = net(images)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "print(classification_report(y_true, y_pred, target_names=classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
